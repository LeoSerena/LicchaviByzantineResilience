{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yellow-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfactory-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.federated_pipeline import Federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1035/1035 [00:00<00:00, 9394.95it/s]\n",
      "  0%|          | 0/1150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [00:00<00:00, 10221.43it/s]\n",
      "100%|██████████| 1374/1374 [00:00<00:00, 10016.38it/s]\n",
      "100%|██████████| 1157/1157 [00:00<00:00, 9175.06it/s]\n",
      "100%|██████████| 1097/1097 [00:00<00:00, 9111.89it/s]\n",
      "100%|██████████| 1010/1010 [00:00<00:00, 9552.95it/s]\n",
      "100%|██████████| 1577/1577 [00:00<00:00, 9226.75it/s]\n",
      "100%|██████████| 1388/1388 [00:00<00:00, 9736.04it/s]\n",
      "100%|██████████| 1673/1673 [00:00<00:00, 9417.18it/s]\n",
      "100%|██████████| 1019/1019 [00:00<00:00, 9625.12it/s]\n"
     ]
    }
   ],
   "source": [
    "federated = Federated(\n",
    "    \"CONFIG_MODEL.json\",\n",
    "    \"CONFIG_FEDERATED.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "northern-morgan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 32.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.91it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:04<00:09,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n",
      "100%|██████████| 10/10 [00:14<00:00,  1.46s/it]\n",
      " 60%|██████    | 6/10 [00:07<00:05,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n",
      "100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n",
      "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "metrics = federated.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "curious-capital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.767432</td>\n",
       "      <td>4.017745</td>\n",
       "      <td>3.837080</td>\n",
       "      <td>2.959029</td>\n",
       "      <td>3.708604</td>\n",
       "      <td>3.793589</td>\n",
       "      <td>2.503214</td>\n",
       "      <td>3.816836</td>\n",
       "      <td>4.398962</td>\n",
       "      <td>3.941298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.371816</td>\n",
       "      <td>3.656954</td>\n",
       "      <td>3.442783</td>\n",
       "      <td>2.647766</td>\n",
       "      <td>3.328164</td>\n",
       "      <td>3.375541</td>\n",
       "      <td>2.259630</td>\n",
       "      <td>3.401452</td>\n",
       "      <td>4.035990</td>\n",
       "      <td>3.548652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.012941</td>\n",
       "      <td>3.327885</td>\n",
       "      <td>3.095615</td>\n",
       "      <td>2.359241</td>\n",
       "      <td>2.997250</td>\n",
       "      <td>3.091289</td>\n",
       "      <td>1.965352</td>\n",
       "      <td>3.141428</td>\n",
       "      <td>3.759351</td>\n",
       "      <td>3.298863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.766324</td>\n",
       "      <td>3.047465</td>\n",
       "      <td>2.873458</td>\n",
       "      <td>2.186348</td>\n",
       "      <td>2.822607</td>\n",
       "      <td>2.854832</td>\n",
       "      <td>1.798676</td>\n",
       "      <td>2.920166</td>\n",
       "      <td>3.570516</td>\n",
       "      <td>3.059479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.577025</td>\n",
       "      <td>2.845127</td>\n",
       "      <td>2.711068</td>\n",
       "      <td>2.053917</td>\n",
       "      <td>2.645216</td>\n",
       "      <td>2.711963</td>\n",
       "      <td>1.657258</td>\n",
       "      <td>2.780058</td>\n",
       "      <td>3.413700</td>\n",
       "      <td>2.909299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4         5         6         7   \\\n",
       "1  3.767432  4.017745  3.837080  2.959029  3.708604  3.793589  2.503214   \n",
       "2  3.371816  3.656954  3.442783  2.647766  3.328164  3.375541  2.259630   \n",
       "3  3.012941  3.327885  3.095615  2.359241  2.997250  3.091289  1.965352   \n",
       "4  2.766324  3.047465  2.873458  2.186348  2.822607  2.854832  1.798676   \n",
       "5  2.577025  2.845127  2.711068  2.053917  2.645216  2.711963  1.657258   \n",
       "\n",
       "         8         9         10  \n",
       "1  3.816836  4.398962  3.941298  \n",
       "2  3.401452  4.035990  3.548652  \n",
       "3  3.141428  3.759351  3.298863  \n",
       "4  2.920166  3.570516  3.059479  \n",
       "5  2.780058  3.413700  2.909299  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indie-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump said he was guilty when vulgar audio donald trump pushed more women to send him into the white house and blind jones in the tape gingrich owes the second phony abc uncovers trump up in nc guardian tomorrow did he read apprentice footage or called thats look at the clintons donald trump is such an idiot why did it not do trump fans trump campaign still arent very much real options matter anymore via an political drip meltdown against him too people dont think the msm must look like it both needs the truth msm maga isis elect trump raise'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated.generate_general('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unable-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump doesnt need to admit that outsider at trumps debate already thinks which he had the attorney he couldnt do whatever he did was a guess due to her dad nevertrump of pardon request that were in too many ways he wont sexually assault its from may have any job as u powerful letter to him all in the love of us not sure what hes himself declared pence wins the whole story then bc he has never liked a pardon of the kind of person to do he should be punished because he was the trump surrogate who couldnt follow'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated.generate_node('trump', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opposite-chosen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump turns fox host news nh oct way hillary clinton is in getting more poll showing trump via forbes clinton for president obama says things to say about americans not a report from ap fake evangelicals showing trump of clinton role model now im best to material this way to learn footage of what a mexican talk like is about you this is a personal kind of conduct or rape who must vote hrc but other than hrc who actually didnt do its worse at hillary t forget the rnc ticket but no longer need to be stronger together than the'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated.generate_node('trump', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "careful-apparatus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump panics after mccain huntsman for president of the election is has started in the right after the next days to vote for him in this week via post via usatoday this is more ignorant no right now but nevertrump is a trump mouthpiece media isnt being ignorant lewd and misogynist language of people magazine gop chairman says it is absolutely a role model for his grabbing and trump should resign the gop nominee is done p s advisor not trump running for office he is like to act on what he does but then going away w him fbi to'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "federated.generate_node('trump', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "representative-pencil",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "N = 100\n",
    "\n",
    "mu_0, sigma_0 = [-1]*N, 0.5\n",
    "mu_1, sigma_1 = [ 1]*N, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = sigma_0 * np.random.randn(d, N) + mu_0\n",
    "data_1 = sigma_1 * np.random.randn(d, N) + mu_1\n",
    "\n",
    "labels_0 = [0] * N\n",
    "labels_1 = [1] * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data_0.T, data_1.T))\n",
    "labels = np.concatenate((labels_0, labels_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = np.column_stack((data.shape[0] * [1], data))\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.data[idx]), torch.FloatTensor([self.labels[idx]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "dataset = SimpleDataset(data, labels)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 4,\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_0[0,:], data_0[1,:])\n",
    "plt.scatter(data_1[0,:], data_1[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self, length):\n",
    "        super().__init__()\n",
    "        self.length = length\n",
    "        self.vector = torch.nn.Parameter(\n",
    "            torch.tensor([-0.5] * length),\n",
    "            requires_grad = True\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(x, self.vector.reshape(self.length, -1))\n",
    "        return torch.sigmoid(x)\n",
    "        \n",
    "    def train(self, dataloader, epochs):\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for x,y in dataloader:\n",
    "                x = self(x)\n",
    "                loss = criterion(x, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "    def evaluate(self, dataloader):\n",
    "        acc = []\n",
    "        with torch.no_grad():\n",
    "            for x,y in dataloader:\n",
    "                x = (self.forward(x) > 1/2)\n",
    "                acc.append(torch.abs(y - x * 1).sum().item() / dataloader.batch_size)\n",
    "        return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = TestModel(d + 1)\n",
    "test_model.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.train(dataloader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_model.vector)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(test_model.parameters(), lr=0.001, momentum=0.9)\n",
    "for x,y in dataloader:\n",
    "    x = test_model.forward(x)\n",
    "    print(test_model.vector)\n",
    "    loss = criterion(x,y)\n",
    "    print(test_model.vector)\n",
    "    loss.backward()\n",
    "    print(test_model.vector)\n",
    "    optimizer.step()\n",
    "    print(test_model.vector)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-filing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('typewriter': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd003343bff8ea9174e4e18dc33629d8cc7123b4a33b966bf5614ca716c9ad2f2e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
