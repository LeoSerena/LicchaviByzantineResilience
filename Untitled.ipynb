{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yellow-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfactory-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.federated_pipeline import Federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1035/1035 [00:00<00:00, 9333.54it/s]\n",
      "  0%|          | 0/1150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1150/1150 [00:00<00:00, 10037.67it/s]\n",
      "100%|██████████| 1374/1374 [00:00<00:00, 10193.93it/s]\n",
      "100%|██████████| 1157/1157 [00:00<00:00, 9194.45it/s]\n",
      "100%|██████████| 1097/1097 [00:00<00:00, 9351.97it/s]\n",
      "100%|██████████| 1010/1010 [00:00<00:00, 9488.93it/s]\n",
      "100%|██████████| 1577/1577 [00:00<00:00, 9322.86it/s]\n",
      "100%|██████████| 1388/1388 [00:00<00:00, 9795.34it/s]\n",
      "100%|██████████| 1673/1673 [00:00<00:00, 9613.94it/s]\n",
      "100%|██████████| 1019/1019 [00:00<00:00, 9914.72it/s] \n"
     ]
    }
   ],
   "source": [
    "federated = Federated(\n",
    "    \"CONFIG_MODEL.json\",\n",
    "    \"CONFIG_FEDERATED.json\",\n",
    "    load_model = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geological-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "northern-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 9/80 [00:00<00:00, 87.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:00<00:00, 112.43it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 119.76it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 117.42it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 120.90it/s]\n",
      "100%|██████████| 88/88 [00:00<00:00, 117.73it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 120.70it/s]\n",
      "100%|██████████| 119/119 [00:00<00:00, 121.47it/s]\n",
      "100%|██████████| 103/103 [00:00<00:00, 115.90it/s]\n",
      "100%|██████████| 139/139 [00:01<00:00, 120.24it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 121.69it/s]\n",
      "100%|██████████| 80/80 [00:00<00:00, 121.73it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 121.72it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 121.32it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 117.19it/s]\n",
      "100%|██████████| 88/88 [00:00<00:00, 118.77it/s]\n",
      "100%|██████████| 78/78 [00:00<00:00, 121.31it/s]\n",
      "100%|██████████| 119/119 [00:00<00:00, 121.02it/s]\n",
      "100%|██████████| 103/103 [00:00<00:00, 121.83it/s]\n",
      "100%|██████████| 139/139 [00:01<00:00, 120.18it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 118.49it/s]\n"
     ]
    }
   ],
   "source": [
    "federated.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "representative-pencil",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "N = 100\n",
    "\n",
    "mu_0, sigma_0 = [-1]*N, 0.5\n",
    "mu_1, sigma_1 = [ 1]*N, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = sigma_0 * np.random.randn(d, N) + mu_0\n",
    "data_1 = sigma_1 * np.random.randn(d, N) + mu_1\n",
    "\n",
    "labels_0 = [0] * N\n",
    "labels_1 = [1] * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data_0.T, data_1.T))\n",
    "labels = np.concatenate((labels_0, labels_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = np.column_stack((data.shape[0] * [1], data))\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.data[idx]), torch.FloatTensor([self.labels[idx]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "dataset = SimpleDataset(data, labels)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 4,\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_0[0,:], data_0[1,:])\n",
    "plt.scatter(data_1[0,:], data_1[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self, length):\n",
    "        super().__init__()\n",
    "        self.length = length\n",
    "        self.vector = torch.nn.Parameter(\n",
    "            torch.tensor([-0.5] * length),\n",
    "            requires_grad = True\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(x, self.vector.reshape(self.length, -1))\n",
    "        return torch.sigmoid(x)\n",
    "        \n",
    "    def train(self, dataloader, epochs):\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for x,y in dataloader:\n",
    "                x = self(x)\n",
    "                loss = criterion(x, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "    def evaluate(self, dataloader):\n",
    "        acc = []\n",
    "        with torch.no_grad():\n",
    "            for x,y in dataloader:\n",
    "                x = (self.forward(x) > 1/2)\n",
    "                acc.append(torch.abs(y - x * 1).sum().item() / dataloader.batch_size)\n",
    "        return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = TestModel(d + 1)\n",
    "test_model.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.train(dataloader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_model.vector)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(test_model.parameters(), lr=0.001, momentum=0.9)\n",
    "for x,y in dataloader:\n",
    "    x = test_model.forward(x)\n",
    "    print(test_model.vector)\n",
    "    loss = criterion(x,y)\n",
    "    print(test_model.vector)\n",
    "    loss.backward()\n",
    "    print(test_model.vector)\n",
    "    optimizer.step()\n",
    "    print(test_model.vector)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-filing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('typewriter': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd003343bff8ea9174e4e18dc33629d8cc7123b4a33b966bf5614ca716c9ad2f2e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
