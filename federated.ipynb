{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yellow-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfactory-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.federated_pipeline import Federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "copyrighted-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    }
   ],
   "source": [
    "federated = Federated(\n",
    "    \"CONFIG_MODEL.json\",\n",
    "    \"CONFIG_FEDERATED.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-morgan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:00<00:00, 28.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.03it/s]\n",
      "100%|██████████| 1295/1295 [00:05<00:00, 242.86it/s]\n",
      " 20%|██        | 2/10 [00:02<00:08,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:04<00:07,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.43s/it]\n",
      "100%|██████████| 1295/1295 [00:05<00:00, 245.32it/s]\n",
      "100%|██████████| 10/10 [00:14<00:00,  1.44s/it]\n",
      "100%|██████████| 1295/1295 [00:05<00:00, 244.44it/s]\n",
      " 80%|████████  | 8/10 [00:11<00:03,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.48s/it]\n",
      " 73%|███████▎  | 944/1295 [00:03<00:01, 243.98it/s]"
     ]
    }
   ],
   "source": [
    "federated.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(federated.general_model_val_losses.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated.generate_general('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated.generate_node('trump', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated.generate_node('trump', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated.generate_node('trump', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated.generate_node('trump', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "N = 100\n",
    "\n",
    "mu_0, sigma_0 = [-1]*N, 0.5\n",
    "mu_1, sigma_1 = [ 1]*N, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = sigma_0 * np.random.randn(d, N) + mu_0\n",
    "data_1 = sigma_1 * np.random.randn(d, N) + mu_1\n",
    "\n",
    "labels_0 = [0] * N\n",
    "labels_1 = [1] * N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data_0.T, data_1.T))\n",
    "labels = np.concatenate((labels_0, labels_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = np.column_stack((data.shape[0] * [1], data))\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.data[idx]), torch.FloatTensor([self.labels[idx]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "dataset = SimpleDataset(data, labels)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 4,\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_0[0,:], data_0[1,:])\n",
    "plt.scatter(data_1[0,:], data_1[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self, length):\n",
    "        super().__init__()\n",
    "        self.length = length\n",
    "        self.vector = torch.nn.Parameter(\n",
    "            torch.tensor([-0.5] * length),\n",
    "            requires_grad = True\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.matmul(x, self.vector.reshape(self.length, -1))\n",
    "        return torch.sigmoid(x)\n",
    "        \n",
    "    def train(self, dataloader, epochs):\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            for x,y in dataloader:\n",
    "                x = self(x)\n",
    "                loss = criterion(x, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "    def evaluate(self, dataloader):\n",
    "        acc = []\n",
    "        with torch.no_grad():\n",
    "            for x,y in dataloader:\n",
    "                x = (self.forward(x) > 1/2)\n",
    "                acc.append(torch.abs(y - x * 1).sum().item() / dataloader.batch_size)\n",
    "        return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = TestModel(d + 1)\n",
    "test_model.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.train(dataloader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.evaluate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_model.vector)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(test_model.parameters(), lr=0.001, momentum=0.9)\n",
    "for x,y in dataloader:\n",
    "    x = test_model.forward(x)\n",
    "    print(test_model.vector)\n",
    "    loss = criterion(x,y)\n",
    "    print(test_model.vector)\n",
    "    loss.backward()\n",
    "    print(test_model.vector)\n",
    "    optimizer.step()\n",
    "    print(test_model.vector)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.federated_pipeline import NullByzantineNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.pickle', 'rb') as f:\n",
    "    vocabulary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'id_' : 1,\n",
    "    'lambda_' : 1e-3,\n",
    "    'p' : 1,\n",
    "    'vocabulary' : vocabulary,\n",
    "    'min_seq_length' : 2,\n",
    "    'max_seq_length' : 20,\n",
    "    'device' : 'cuda:0'\n",
    "}\n",
    "\n",
    "nbn = NullByzantineNode(\n",
    "    **parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbn.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-student",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('typewriter': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd003343bff8ea9174e4e18dc33629d8cc7123b4a33b966bf5614ca716c9ad2f2e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
