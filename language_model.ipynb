{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minus-radiation",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import typing\n",
    "import gc\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.join('..','src')\n",
    ")\n",
    "\n",
    "from src.models import NextWordPredictorModel\n",
    "from src.data_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ultimate-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tropical-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-startup",
   "metadata": {},
   "source": [
    "## Global Variables & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brazilian-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "assert torch.cuda.is_available()\n",
    "from apex import amp, optimizers\n",
    "\n",
    "MIN_SEQ_LEN = 2\n",
    "MAX_SEQ_LEN = 20\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_LSTM_LAYERS = 2\n",
    "EMB_SIZE = 128\n",
    "HIDDEN_STATE_SIZE = 100\n",
    "DROPOUT = 0.5\n",
    "fp16 = True\n",
    "POS_ENCODING = False\n",
    "STARTING_LR = 1e-3\n",
    "\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "\n",
    "# for reproducibility\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-excuse",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "internal-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "train_text = ' '.join(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "juvenile-temple",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary = FromRawTextVocabulary(\n",
    "    text = train_text,\n",
    "    tokenizer = tokenizer,\n",
    "    text_cleaner = None,\n",
    "    max_voc_size = 10000,\n",
    "    min_word_occ = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-barcelona",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dominican-burton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "\n",
    "train_text = ' '.join(train_iter)\n",
    "val_text = ' '.join(val_iter)\n",
    "test_text = ' '.join(test_iter)\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = train_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "val_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = val_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = test_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "\n",
    "del train_text\n",
    "del val_text\n",
    "del test_text\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pleasant-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = False,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "imposed-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_weights(weights, m_ = 0.01, M_ = 1):\n",
    "    weights = 1 / weights\n",
    "    M, m = max(weights), min(weights)\n",
    "    return (np.array(weights) - m) * (M_ - m_) / (M - m) + m_\n",
    "\n",
    "weights = map_weights(np.array(list(vocabulary.vocab.values())))\n",
    "weights = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-waterproof",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "willing-express",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    }
   ],
   "source": [
    "model = NextWordPredictorModel(\n",
    "    type_of_rnn = 'GRU',\n",
    "    emb_dim  = EMB_SIZE,\n",
    "    vocab_size = vocabulary.get_vocab_size(),\n",
    "    num_lstm_hidden_layers = NUM_LSTM_LAYERS,\n",
    "    hidden_state_size = HIDDEN_STATE_SIZE,\n",
    "    dropout = DROPOUT,\n",
    "    device = DEVICE,\n",
    "    lr = STARTING_LR,\n",
    "    fp16 = fp16,\n",
    "    weight = weights,\n",
    "    positional_encoding = POS_ENCODING\n",
    ").to(DEVICE)\n",
    "\n",
    "if fp16:\n",
    "    model, model.optimizer = amp.initialize(\n",
    "        model,\n",
    "        model.optimizer,\n",
    "        opt_level = 'O1' # https://nvidia.github.io/apex/amp.html\n",
    "    )\n",
    "\n",
    "model.scheduler = torch.optim.lr_scheduler.StepLR(model.optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-webmaster",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lightweight-monroe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [00:29<00:00, 230.70it/s]\n",
      "100%|██████████| 700/700 [00:03<00:00, 231.65it/s]\n",
      "  0%|          | 7/6870 [00:00<01:45, 65.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 0 : 9.618661440720205\n",
      "Eval loss at epoch 0 : 9.618544528143747\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:24<00:00, 81.19it/s]\n",
      "100%|██████████| 700/700 [00:03<00:00, 229.99it/s]\n",
      "  0%|          | 7/6870 [00:00<01:47, 63.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 1 : 6.593687974660504\n",
      "Eval loss at epoch 1 : 6.217376847948347\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 2093/6870 [00:26<00:58, 81.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 4112/6870 [00:51<00:33, 81.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 5470/6870 [01:08<00:17, 80.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:25<00:00, 80.49it/s]\n",
      "100%|██████████| 700/700 [00:03<00:00, 229.55it/s]\n",
      "  0%|          | 7/6870 [00:00<01:45, 64.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 2 : 6.212496423929539\n",
      "Eval loss at epoch 2 : 6.104547550337656\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1086/6870 [00:13<01:11, 81.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3785/6870 [00:46<00:37, 81.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 5809/6870 [01:11<00:12, 82.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:24<00:00, 80.92it/s]\n",
      "100%|██████████| 700/700 [00:03<00:00, 229.46it/s]\n",
      "  0%|          | 8/6870 [00:00<01:27, 78.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 3 : 6.119169737956062\n",
      "Eval loss at epoch 3 : 6.04739938054766\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1636/6870 [00:20<01:03, 81.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3803/6870 [00:46<00:37, 81.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 6008/6870 [01:14<00:10, 80.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:24<00:00, 80.83it/s]\n",
      "100%|██████████| 700/700 [00:03<00:00, 229.84it/s]\n",
      "  0%|          | 8/6870 [00:00<01:29, 76.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 4 : 6.06952777734837\n",
      "Eval loss at epoch 4 : 6.017787205832345\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1205/6870 [00:14<01:09, 81.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 3220/6870 [00:39<00:44, 81.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 5236/6870 [01:04<00:20, 81.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:25<00:00, 80.82it/s]\n",
      "100%|██████████| 700/700 [00:03<00:00, 229.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 5 : 6.038457055695713\n",
      "Eval loss at epoch 5 : 6.000528519494193\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.fit(\n",
    "    train_dataloader = train_dataloader,\n",
    "    eval_dataloader = val_dataloader,\n",
    "    num_epochs = 5,\n",
    "    early_stopping = True,\n",
    "    early_stopping_patience = 2,\n",
    "    early_stopping_metric = 'val_loss',\n",
    "    early_stopping_metric_best = 'min', # if lower is better (like for loss)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respected-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics).T\n",
    "plt.figure()\n",
    "plt.plot(df['train_loss'])\n",
    "plt.plot(df['val_loss'])\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-scout",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "innocent-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2595, 1389, 5, 2, 3086, 3, 29, 252, 51, 4, 14, 175, 3223, 6, 2, 1014, 3684, 1794, 3, 373, 6, 0, 2, 757]\n"
     ]
    }
   ],
   "source": [
    "sent = 'Historians write in the context of their own time and with due regard to the current dominant ideas of how to interpret the past'\n",
    "ind = [train_dataset.get_idx(w.lower()) for w in sent.split(' ')]\n",
    "print(ind)\n",
    "hidden = model.init_hidden(1)\n",
    "inputs = torch.tensor([ind]).to(DEVICE)\n",
    "model.eval()\n",
    "output, _ = model(inputs, hidden)\n",
    "preds = output.view(-1, model.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "apart-parts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of', 'are', 'and']\n",
      "['that', 'the', 'a']\n",
      "['the', 'a', 'this']\n",
      "['world', 'game', 'same']\n",
      "['of', 'and', 'as']\n",
      "['the', 'a', 'his']\n",
      "['own', 'life', 'and']\n",
      "['and', 'life', 'as']\n",
      "['and', 'in', 'the']\n",
      "['the', 'a', 'other']\n",
      "['the', 'a', 'their']\n",
      "['to', 'for', 'from']\n",
      "['to', 'the', 'by']\n",
      "['the', 'a', 'their']\n",
      "['church', 'world', 'city']\n",
      "['and', 'century', 'level']\n",
      "['and', 'in', 'of']\n",
      "['of', 'and', 'for']\n",
      "['the', 'a', 'their']\n",
      "['the', 'it', 'to']\n",
      "['the', 'be', 'have']\n",
      "['the', 'and', 'their']\n",
      "['song', 'same', 'world']\n",
      "['the', 'and', 'a']\n"
     ]
    }
   ],
   "source": [
    "for top4 in preds.topk(3).indices:\n",
    "    res = []\n",
    "    for l in top4:\n",
    "        w = vocabulary.idx_to_word[l.item()]\n",
    "        res.append(w)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "declared-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "compact-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [00:29<00:00, 235.75it/s]\n",
      "100%|██████████| 700/700 [00:02<00:00, 238.34it/s]\n",
      "  0%|          | 8/6870 [00:00<01:34, 72.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 0 : 5.869343998824318\n",
      "Eval loss at epoch 0 : 5.951654611996242\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 541/6870 [00:06<01:11, 88.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 3197/6870 [00:36<00:41, 88.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 5412/6870 [01:01<00:16, 88.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:17<00:00, 88.31it/s]\n",
      "100%|██████████| 700/700 [00:02<00:00, 235.96it/s]\n",
      "  0%|          | 8/6870 [00:00<01:32, 74.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 1 : 5.948602914740772\n",
      "Eval loss at epoch 1 : 5.944996579715184\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1078/6870 [00:12<01:05, 88.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 4924/6870 [00:56<00:21, 88.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:18<00:00, 87.88it/s]\n",
      "100%|██████████| 700/700 [00:02<00:00, 236.35it/s]\n",
      "  0%|          | 8/6870 [00:00<01:25, 79.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 2 : 5.937287572169408\n",
      "Eval loss at epoch 2 : 5.935415239334106\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 125/6870 [00:01<01:18, 85.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 2492/6870 [00:28<00:49, 88.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 6505/6870 [01:14<00:04, 89.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:18<00:00, 87.80it/s]\n",
      "100%|██████████| 700/700 [00:02<00:00, 238.79it/s]\n",
      "  0%|          | 9/6870 [00:00<01:23, 82.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 3 : 5.929110312635374\n",
      "Eval loss at epoch 3 : 5.931431913375855\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1636/6870 [00:18<00:58, 88.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2568/6870 [00:29<00:48, 88.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 3785/6870 [00:42<00:34, 88.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 131072.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:17<00:00, 88.45it/s]\n",
      "100%|██████████| 700/700 [00:02<00:00, 238.10it/s]\n",
      "  0%|          | 8/6870 [00:00<01:27, 78.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 4 : 5.923672549207485\n",
      "Eval loss at epoch 4 : 5.9318472712380546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 953/6870 [00:10<01:06, 88.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 3647/6870 [00:41<00:36, 88.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5727/6870 [01:05<00:12, 88.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 262144.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6870/6870 [01:18<00:00, 87.70it/s]\n",
      "100%|██████████| 700/700 [00:02<00:00, 235.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 5 : 5.9180255427631225\n",
      "Eval loss at epoch 5 : 5.920863290514265\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.fit(\n",
    "    train_dataloader = train_dataloader,\n",
    "    eval_dataloader = val_dataloader,\n",
    "    num_epochs = 5,\n",
    "    early_stopping = True,\n",
    "    early_stopping_patience = 2,\n",
    "    early_stopping_metric = 'val_loss',\n",
    "    early_stopping_metric_best = 'min', # if lower is better (like for loss)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-easter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('typewriter': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd003343bff8ea9174e4e18dc33629d8cc7123b4a33b966bf5614ca716c9ad2f2e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
