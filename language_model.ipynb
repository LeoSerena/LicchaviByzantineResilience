{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minus-radiation",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ultimate-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import webtext\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-startup",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brazilian-immigration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efd22be7f90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "\n",
    "PADDING_TOKEN = 'PAD' # voc 0\n",
    "UNKNOWN_TOKEN = 'UKN' # voc 1\n",
    "\n",
    "MAX_SEQ_LEN = 10\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EMB_SIZE = 128\n",
    "\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "\n",
    "# for reproducibility\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-excuse",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minute-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary():\n",
    "    def __init__(\n",
    "        self, \n",
    "        text,\n",
    "        max_sentence_length : int = 32,\n",
    "        padding_token : str = PADDING_TOKEN,\n",
    "        unknown_token : str = UNKNOWN_TOKEN\n",
    "    ):\n",
    "        self.padding_token = padding_token\n",
    "        self.unknown_token = unknown_token\n",
    "        self.sentences = Vocabulary.prepare_sentences(text, max_sentence_length)\n",
    "        self.build_vocab()\n",
    "        \n",
    "    @staticmethod\n",
    "    def text_cleaning(string):\n",
    "        string = re.sub('-\\n', '', string)\n",
    "        string = re.sub(r\"\"\"[*#@&%£ö'ä$ü¨~^)('+°¢./><$\\[\\]`]\"\"\", '', string)\n",
    "        string = re.sub('[0-9]', '', string)\n",
    "        return re.sub('\\n', ' ', string)\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_sentences(text, max_sentence_length):\n",
    "        sentences = sent_tokenize(text)\n",
    "        sentences = [re.sub(r\".*: \", '', sent, 1) for sent in sentences]\n",
    "        sentences = [Vocabulary.text_cleaning(sentence) for sentence in sentences]\n",
    "        sentences = [[w.lower() for w in nltk.word_tokenize(sentence)] for sentence in sentences]\n",
    "        return [sent for sent in sentences if len(sent) < max_sentence_length]\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        vocab = {}\n",
    "        for tokens in self.sentences:\n",
    "            for token in tokens:\n",
    "                if token in vocab.keys():\n",
    "                    vocab[token] += 1\n",
    "                else:\n",
    "                    vocab[token] = 1\n",
    "\n",
    "        self.vocab = {k: v for k, v in sorted(vocab.items(), key=lambda item: -item[1])}\n",
    "\n",
    "        self.word_to_idx = {k : (i+2) for i,(k,_) in enumerate(vocab.items())}\n",
    "        self.word_to_idx[self.padding_token] = 0\n",
    "        self.word_to_idx[self.unknown_token] = 1\n",
    "        self.idx_to_word = {v : k for k, v in self.word_to_idx.items()}\n",
    "        \n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def pad_and_truncate(self, tokens, max_length):\n",
    "        diff = max_length - len(tokens)\n",
    "        if diff < 0:\n",
    "            return tokens[:max_length]\n",
    "        else:\n",
    "            return tokens + [self.word_to_idx[self.padding_token]] * diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worse-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = webtext.raw('overheard.txt')\n",
    "voc = Vocabulary(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adapted-victor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(sent) for sent in voc.sentences], bins = 32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "necessary-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocabulary : Vocabulary,\n",
    "        max_length : int\n",
    "    ):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_length = max_length\n",
    "        self.indices = [\n",
    "            self.vocabulary.pad_and_truncate([self.get_idx(w) for w in sentence], max_length + 1)\n",
    "            for sentence in vocabulary.sentences if len(sentence) > 1\n",
    "        ]\n",
    "        \n",
    "    def get_idx(self, token):\n",
    "        try:\n",
    "            return self.vocabulary.word_to_idx[token]\n",
    "        except KeyError:\n",
    "            return self.vocabulary.word_to_idx[self.vocabulary.unknown_token]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        indices = self.indices[idx]\n",
    "        return (\n",
    "            torch.tensor(indices[:self.max_length]).to(DEVICE),\n",
    "            torch.tensor(indices[1:self.max_length+1]).to(DEVICE)\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comparable-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LM_dataset(\n",
    "    voc,\n",
    "    MAX_SEQ_LEN + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pleasant-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "global-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = torch.nn.Embedding(\n",
    "    voc.get_vocab_size(),\n",
    "    EMB_SIZE\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "average-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = torch.nn.LSTM(\n",
    "    input_size = EMB_SIZE,\n",
    "    hidden_size = 20,\n",
    "    num_layers = 2,\n",
    "    batch_first = True\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "above-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextWordPredictorModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim : int,\n",
    "        vocab_size : int,\n",
    "        num_lstm_hidden_layers : int,\n",
    "        hidden_state_size : int,\n",
    "        dropout : float,\n",
    "        device : str,\n",
    "        fp16 : bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_lstm_hidden_layers = num_lstm_hidden_layers\n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.device = device\n",
    "        self.fp16 = False\n",
    "        self.vocab_size = vocab_size\n",
    "        # Embedding layer\n",
    "        self.embedding_layer = torch.nn.Embedding(\n",
    "            self.vocab_size,\n",
    "            emb_dim\n",
    "        ).to(device)\n",
    "        # LSTM layer (later replace with oupled Input and Forget Gate (CIFG) maybe)\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = emb_dim,\n",
    "            hidden_size = hidden_state_size,\n",
    "            num_layers = num_lstm_hidden_layers,\n",
    "            dropout = dropout,\n",
    "            batch_first = True # -> input of the shape (bath size, seq length, emb length)\n",
    "        ).to(device)\n",
    "        # FFN for classification on vocab\n",
    "        self.classifier = torch.nn.Linear(\n",
    "            hidden_state_size,\n",
    "            self.vocab_size\n",
    "        ).to(device)\n",
    "        # softmax for classification\n",
    "        self.softmax = torch.nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "        self.hidden_state = None\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr = 10e-4\n",
    "        )\n",
    "        \n",
    "        self.criterion = torch.nn.NLLLoss(\n",
    "            ignore_index = 0\n",
    "        )#.to(device) # may use the weight as prior n_occ / num_words\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        if self.hidden_state is None:\n",
    "            # in the case forward is called for testing, init the states at 0\n",
    "            self.state = self.init_hidden(inputs.shape[0])\n",
    "        embeddings = self.embedding_layer(inputs)\n",
    "        output, self.state = self.lstm(embeddings, self.state)\n",
    "        return self.classifier(output)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (\n",
    "            torch.zeros(\n",
    "                self.num_lstm_hidden_layers, batch_size, self.hidden_state_size\n",
    "            ).to(self.device),\n",
    "            torch.zeros(\n",
    "                self.num_lstm_hidden_layers, batch_size, self.hidden_state_size\n",
    "            ).to(self.device)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def epoch_step(self, data_loader):\n",
    "        self.train()\n",
    "        losses = []\n",
    "        \n",
    "        self.init_hidden(data_loader.batch_size)\n",
    "        \n",
    "        for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "            for param in self.parameters():\n",
    "                param.grad = None\n",
    "                \n",
    "            inputs, labels = batch\n",
    "            outputs = self.forward(inputs)\n",
    "            preds = self.softmax(outputs).view(-1, voc.get_vocab_size())\n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "            loss = self.criterion(preds, labels)\n",
    "            \n",
    "            if self.fp16:\n",
    "                with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                self.optimizer.step()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "    \n",
    "            losses.append(loss.item())\n",
    "                \n",
    "        return losses\n",
    "    \n",
    "    def fit(self, data_loader, num_epochs):\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            losses = self.epoch_step(data_loader)\n",
    "            train_loss = np.mean(losses)\n",
    "            print(f\"train loss at epoch {epoch} : {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "willing-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NextWordPredictorModel(\n",
    "    emb_dim  = EMB_SIZE,\n",
    "    vocab_size = voc.get_vocab_size(),\n",
    "    num_lstm_hidden_layers = 2,\n",
    "    hidden_state_size = 32,\n",
    "    dropout = 0.2,\n",
    "    device = DEVICE,\n",
    "    fp16 = False\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "military-delicious",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1058/1058 [00:03<00:00, 267.86it/s]\n",
      "  3%|▎         | 27/1058 [00:00<00:03, 267.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 1 : 1.8924977801923266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1058/1058 [00:03<00:00, 271.46it/s]\n",
      "  3%|▎         | 27/1058 [00:00<00:03, 267.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 2 : 1.4780018333000586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1058/1058 [00:03<00:00, 272.56it/s]\n",
      "  3%|▎         | 28/1058 [00:00<00:03, 272.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 3 : 1.2655862435726677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1058/1058 [00:03<00:00, 272.05it/s]\n",
      "  3%|▎         | 28/1058 [00:00<00:03, 272.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 4 : 1.1219863254429037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1058/1058 [00:03<00:00, 272.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 5 : 1.0165940505683084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataloader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-avenue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('typewriter': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd003343bff8ea9174e4e18dc33629d8cc7123b4a33b966bf5614ca716c9ad2f2e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
