{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minus-radiation",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ultimate-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import webtext\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-startup",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "brazilian-immigration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb840b549f0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "\n",
    "PADDING_TOKEN = 'PAD' # voc 0\n",
    "UNKNOWN_TOKEN = 'UKN' # voc 1\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EMB_SIZE = 128\n",
    "\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "\n",
    "# for reproducibility\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-excuse",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "minute-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary():\n",
    "    def __init__(\n",
    "        self, \n",
    "        text,\n",
    "        max_sentence_length : int = 32,\n",
    "        padding_token : str = PADDING_TOKEN,\n",
    "        unknown_token : str = UNKNOWN_TOKEN\n",
    "    ):\n",
    "        self.padding_token = padding_token\n",
    "        self.unknown_token = unknown_token\n",
    "        self.sentences = Vocabulary.prepare_sentences(text, max_sentence_length)\n",
    "        self.build_vocab()\n",
    "        \n",
    "    @staticmethod\n",
    "    def text_cleaning(string):\n",
    "        string = re.sub('-\\n', '', string)\n",
    "        string = re.sub(r\"\"\"[*#@&%£ö'ä$ü¨~^)('+°¢./><$\\[\\]`]\"\"\", '', string)\n",
    "        string = re.sub('[0-9]', '', string)\n",
    "        return re.sub('\\n', ' ', string)\n",
    "    \n",
    "    @staticmethod\n",
    "    def prepare_sentences(text, max_sentence_length):\n",
    "        sentences = sent_tokenize(text)\n",
    "        sentences = [re.sub(r\".*: \", '', sent, 1) for sent in sentences]\n",
    "        sentences = [Vocabulary.text_cleaning(sentence) for sentence in sentences]\n",
    "        sentences = [[w.lower() for w in nltk.word_tokenize(sentence)] for sentence in sentences]\n",
    "        return [sent for sent in sentences if len(sent) < max_sentence_length]\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        vocab = {}\n",
    "        for tokens in self.sentences:\n",
    "            for token in tokens:\n",
    "                if token in vocab.keys():\n",
    "                    vocab[token] += 1\n",
    "                else:\n",
    "                    vocab[token] = 1\n",
    "\n",
    "        self.vocab = {k: v for k, v in sorted(vocab.items(), key=lambda item: -item[1])}\n",
    "\n",
    "        self.word_to_idx = {k : (i+2) for i,(k,_) in enumerate(vocab.items())}\n",
    "        self.word_to_idx[self.padding_token] = 0\n",
    "        self.word_to_idx[self.unknown_token] = 1\n",
    "        self.idx_to_word = {v : k for k, v in word_to_idx.items()}\n",
    "        \n",
    "    def get_vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def pad_and_truncate(self, tokens, max_length):\n",
    "        diff = max_length - len(tokens)\n",
    "        if diff < 0:\n",
    "            return tokens[:max_length]\n",
    "        else:\n",
    "            return tokens + [self.word_to_idx[self.padding_token]] * diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "worse-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = webtext.raw('overheard.txt')\n",
    "voc = Vocabulary(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "adapted-victor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(sent) for sent in voc.sentences], bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "necessary-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocabulary : Vocabulary,\n",
    "        max_length : int\n",
    "    ):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_length = max_length\n",
    "        self.indices = [\n",
    "            self.vocabulary.pad_and_truncate([self.get_idx(w) for w in sentence], max_length + 1)\n",
    "            for sentence in vocabulary.sentences if len(sentence) > 1\n",
    "        ]\n",
    "        \n",
    "    def get_idx(self, token):\n",
    "        try:\n",
    "            return self.vocabulary.word_to_idx[token]\n",
    "        except KeyError:\n",
    "            return self.vocabulary.word_to_idx[self.vocabulary.unknown_token]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'inputs' : torch.LongTensor(self.indices[idx][:self.max_length]).to(DEVICE),\n",
    "            'labels' : torch.LongTensor(self.indices[idx][1:self.max_length+1]).to(DEVICE)\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "comparable-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LM_dataset(\n",
    "    voc,\n",
    "    10 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "pleasant-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    pin_memory = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "global-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = torch.nn.Embedding(\n",
    "    VOCAB_SIZE,\n",
    "    EMB_SIZE\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "average-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = torch.nn.LSTM(\n",
    "    input_size = EMB_SIZE,\n",
    "    hidden_size = 20,\n",
    "    num_layers = 2,\n",
    "    batch_first = True\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "abandoned-selling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 128])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = emb_layer(train_dataset[1:3]['inputs'])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "emotional-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.randn(2, 2, 20).to(DEVICE)\n",
    "c0 = torch.randn(2, 2, 20).to(DEVICE)\n",
    "output, (hn,cn) = lstm(tensor, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "thermal-hometown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 20])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "august-samba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 20])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "intensive-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 20])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "above-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextWordPredictorModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim : int,\n",
    "        vocab_size : int,\n",
    "        num_lstm_hidden_layers : int,\n",
    "        hidden_state_size : int,\n",
    "        dropout : float,\n",
    "        device : str\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_lstm_hidden_layers = num_lstm_hidden_layers\n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.device = device\n",
    "        # Embedding layer\n",
    "        self.embedding_layer = torch.nn.Embedding(\n",
    "            vocab_size,\n",
    "            emb_dim\n",
    "        ).to(device)\n",
    "        # LSTM layer (later replace with oupled Input and Forget Gate (CIFG) maybe)\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = emb_dim,\n",
    "            hidden_size = hidden_state_size,\n",
    "            num_layers = num_lstm_hidden_layers,\n",
    "            dropout = dropout,\n",
    "            batch_first = True # -> input of the shape (bath size, seq length, emb length)\n",
    "        ).to(device)\n",
    "        # FFN for classification on vocab\n",
    "        self.classifier = torch.nn.Linear(\n",
    "            hidden_state_size,\n",
    "            vocab_size\n",
    "        ).to(device)\n",
    "        \n",
    "        self.hidden_state = None\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr = 10e-4\n",
    "        )\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(\n",
    "            ignore_index = 0,\n",
    "            reduction = 'None'\n",
    "        ).to(device) # may use the weight as prior n_occ / num_words\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        if self.hidden_state is None:\n",
    "            # in the case forward is called for testing, init the states at 0\n",
    "            self.state = self.init_hidden(inputs.shape[0])\n",
    "        embeddings = self.embedding_layer(inputs)\n",
    "        output, self.state = self.lstm(embeddings, self.state)\n",
    "        forward = self.classifier(output)\n",
    "        return torch.nn.functional.log_softmax(forward, dim = 1)\n",
    "                \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (\n",
    "            torch.zeros(\n",
    "                self.num_lstm_hidden_layers, batch_size, self.hidden_state_size\n",
    "            ).to(self.device),\n",
    "            torch.zeros(\n",
    "                self.num_lstm_hidden_layers, batch_size, self.hidden_state_size\n",
    "            ).to(self.device)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def epoch_step(self, data_loader):\n",
    "        self.train()\n",
    "        losses = []\n",
    "        \n",
    "        self.init_hidden(data_loader.batch_size)\n",
    "        \n",
    "        for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "            for param in self.parameters():\n",
    "                param.grad = None\n",
    "            \n",
    "            target = batch.pop('labels')\n",
    "            output = self.forward(batch['inputs'])\n",
    "            loss = self.criterion(output, target)\n",
    "            \n",
    "            if self.fp16:\n",
    "                with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                self.optimizer.step()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "    \n",
    "            losses.append(loss.item())\n",
    "                \n",
    "        return losses\n",
    "    \n",
    "    def fit(self, num_epochs):\n",
    "        for epoch in range(1, epochs+1):\n",
    "            losses = self.epoch_step(train_data_loader, history, epoch)\n",
    "            train_loss = np.mean(losses)\n",
    "            print(f\"train loss at epoch {epoch} : {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "willing-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NextWordPredictorModel(\n",
    "    emb_dim  = EMB_SIZE,\n",
    "    vocab_size = voc.get_vocab_size(),\n",
    "    num_lstm_hidden_layers = 2,\n",
    "    hidden_state_size = 32,\n",
    "    dropout = 0.2,\n",
    "    device = DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "fitted-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = train_dataset[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "every-innocent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.4440, -2.3661, -2.3807,  ..., -2.4076, -2.3556, -2.4359],\n",
       "         [-2.4662, -2.3759, -2.4001,  ..., -2.3946, -2.3562, -2.4089],\n",
       "         [-2.4477, -2.4141, -2.3932,  ..., -2.3781, -2.3804, -2.3922],\n",
       "         ...,\n",
       "         [-2.3438, -2.4103, -2.4104,  ..., -2.4173, -2.4361, -2.3847],\n",
       "         [-2.3513, -2.3971, -2.4090,  ..., -2.4324, -2.4264, -2.3792],\n",
       "         [-2.3705, -2.4002, -2.4078,  ..., -2.4264, -2.4463, -2.3797]],\n",
       "\n",
       "        [[-2.3581, -2.3924, -2.3611,  ..., -2.4255, -2.4241, -2.3823],\n",
       "         [-2.3863, -2.4049, -2.3813,  ..., -2.4033, -2.4183, -2.3682],\n",
       "         [-2.3997, -2.4219, -2.3798,  ..., -2.4115, -2.4417, -2.3707],\n",
       "         ...,\n",
       "         [-2.4104, -2.4096, -2.4170,  ..., -2.3691, -2.3697, -2.4101],\n",
       "         [-2.3885, -2.3732, -2.4199,  ..., -2.4096, -2.3719, -2.4234],\n",
       "         [-2.3947, -2.3970, -2.4236,  ..., -2.3910, -2.3531, -2.4272]],\n",
       "\n",
       "        [[-2.3744, -2.3776, -2.3645,  ..., -2.4510, -2.4231, -2.4171],\n",
       "         [-2.3957, -2.3905, -2.3842,  ..., -2.4213, -2.4008, -2.3888],\n",
       "         [-2.3885, -2.4020, -2.3976,  ..., -2.4147, -2.4114, -2.3883],\n",
       "         ...,\n",
       "         [-2.4155, -2.3995, -2.4038,  ..., -2.3619, -2.3720, -2.4010],\n",
       "         [-2.3982, -2.4015, -2.4058,  ..., -2.3850, -2.3649, -2.4164],\n",
       "         [-2.4054, -2.3918, -2.3983,  ..., -2.3705, -2.3533, -2.4132]]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(test_tensor['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "military-delicious",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1059 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target size (16, 9662), got torch.Size([16, 10])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-332-8efc662c1bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-328-652b560c974e>\u001b[0m in \u001b[0;36mepoch_step\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/typewriter/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/typewriter/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/typewriter/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/typewriter/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         \u001b[0mout_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0m\u001b[1;32m   2274\u001b[0m                 out_size, target.size()))\n\u001b[1;32m   2275\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (16, 9662), got torch.Size([16, 10])"
     ]
    }
   ],
   "source": [
    "model.epoch_step(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "sunrise-reviewer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-chair",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('typewriter': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd003343bff8ea9174e4e18dc33629d8cc7123b4a33b966bf5614ca716c9ad2f2e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
