{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minus-radiation",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import typing\n",
    "import gc\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.join('.','src')\n",
    ")\n",
    "\n",
    "from src.models import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pharmaceutical-width",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline('CONFIG.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextWordPredictorModel(\n",
       "  (embedding_layer): Embedding(10000, 256, padding_idx=0)\n",
       "  (rnn): GRU(256, 200, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=200, out_features=10000, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appropriate-holder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:16<00:00, 436.94it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 438.00it/s]\n",
      "  0%|          | 12/7100 [00:00<01:01, 114.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 0 : 9.20924391719657\n",
      "Eval loss at epoch 0 : 9.20965210508905\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:52<00:00, 134.81it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 433.45it/s]\n",
      "  0%|          | 12/7100 [00:00<01:00, 116.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 1 : 6.1744117244532415\n",
      "Eval loss at epoch 1 : 5.703722881348752\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1062/7100 [00:07<00:44, 137.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 3390/7100 [00:25<00:29, 125.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 5598/7100 [00:43<00:11, 127.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:55<00:00, 127.96it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 391.36it/s]\n",
      "  0%|          | 0/7100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 2 : 5.5271706914901735\n",
      "Eval loss at epoch 2 : 5.513788304276229\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 820/7100 [00:06<00:51, 122.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 3241/7100 [00:25<00:30, 127.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 5334/7100 [00:42<00:14, 120.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:56<00:00, 124.77it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 390.40it/s]\n",
      "  0%|          | 12/7100 [00:00<01:02, 112.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 3 : 5.278839963053314\n",
      "Eval loss at epoch 3 : 5.450446323795213\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 376/7100 [00:03<00:53, 126.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2377/7100 [00:19<00:37, 125.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 4597/7100 [00:37<00:19, 125.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:57<00:00, 123.36it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 393.81it/s]\n",
      "  0%|          | 0/7100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 4 : 5.127588445233627\n",
      "Eval loss at epoch 4 : 5.426817983553555\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 115/7100 [00:00<00:54, 127.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2598/7100 [00:20<00:35, 126.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 4808/7100 [00:38<00:18, 126.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 6965/7100 [00:55<00:01, 123.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:57<00:00, 124.41it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 393.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 5 : 5.016937664058847\n",
      "Eval loss at epoch 5 : 5.413711583087458\n",
      "updating best metric\n"
     ]
    }
   ],
   "source": [
    "pipeline.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recognized-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6531/6531 [00:09<00:00, 723.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.410678762404665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    pipeline.test_dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = False,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "pipeline.model.evaluate(\n",
    "    test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ultimate-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-startup",
   "metadata": {},
   "source": [
    "## Global Variables & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "assert torch.cuda.is_available()\n",
    "from apex import amp, optimizers\n",
    "\n",
    "MIN_SEQ_LEN = 2\n",
    "MAX_SEQ_LEN = 20\n",
    "\n",
    "RNN_TYPE = 'LSTM'\n",
    "BATCH_SIZE = 16\n",
    "NUM_RNN_LAYERS = 4\n",
    "EMB_SIZE = 256\n",
    "HIDDEN_STATE_SIZE = 200\n",
    "DROPOUT = 0.5\n",
    "fp16 = True\n",
    "POS_ENCODING = False\n",
    "STARTING_LR = 5e-4\n",
    "LAMBDA = 0\n",
    "p = 1\n",
    "\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "\n",
    "# for reproducibility\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-excuse",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "train_text = ' '.join(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-temple",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary = FromRawTextVocabulary(\n",
    "    text = train_text,\n",
    "    tokenizer = tokenizer,\n",
    "    text_cleaner = None,\n",
    "    max_voc_size = 10000,\n",
    "    min_word_occ = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-barcelona",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "\n",
    "train_text = ' '.join(train_iter)\n",
    "val_text = ' '.join(val_iter)\n",
    "test_text = ' '.join(test_iter)\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = train_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "val_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = val_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = test_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "\n",
    "del train_text\n",
    "del val_text\n",
    "del test_text\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = False,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_weights(weights, m_ = 0.01, M_ = 1):\n",
    "    weights = 1 / weights\n",
    "    M, m = max(weights), min(weights)\n",
    "    return (np.array(weights) - m) * (M_ - m_) / (M - m) + m_\n",
    "\n",
    "weights = map_weights(np.array(list(vocabulary.vocab.values())))\n",
    "weights = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-waterproof",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NextWordPredictorModel(\n",
    "    type_of_rnn = RNN_TYPE,\n",
    "    emb_dim  = EMB_SIZE,\n",
    "    vocab_size = vocabulary.get_vocab_size(),\n",
    "    num_rnn_hidden_layers = NUM_RNN_LAYERS,\n",
    "    hidden_state_size = HIDDEN_STATE_SIZE,\n",
    "    dropout = DROPOUT,\n",
    "    device = DEVICE,\n",
    "    weight = weights,\n",
    "    positional_encoding = POS_ENCODING\n",
    ").to(DEVICE)\n",
    "\n",
    "# need to setup the optimizer there because of the amp initialization\n",
    "model.optimizer = torch.optim.Adam(model.parameters(), lr = STARTING_LR)\n",
    "\n",
    "if fp16:\n",
    "    model, model.optimizer = amp.initialize(\n",
    "        model,\n",
    "        model.optimizer,\n",
    "        opt_level = 'O1' # https://nvidia.github.io/apex/amp.html\n",
    "    )\n",
    "\n",
    "model.scheduler = torch.optim.lr_scheduler.StepLR(model.optimizer, 1.0, gamma=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-webmaster",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-monroe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = model.fit(\n",
    "    train_dataloader = train_dataloader,\n",
    "    eval_dataloader = val_dataloader,\n",
    "    num_epochs = 20,\n",
    "    fp16 = fp16,\n",
    "    p = p,\n",
    "    lambda_ = LAMBDA,\n",
    "    early_stopping = True,\n",
    "    early_stopping_patience = 2,\n",
    "    early_stopping_metric = 'val_loss',\n",
    "    early_stopping_metric_best = 'min', # if lower is better (like for loss)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics).T\n",
    "plt.figure()\n",
    "plt.plot(df['train_loss'])\n",
    "plt.plot(df['val_loss'])\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-scout",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Historians write in the context of their own time and with due regard to the current dominant ideas of how to interpret the past'\n",
    "ind = [train_dataset.get_idx(w.lower()) for w in sent.split(' ')]\n",
    "print(ind)\n",
    "hidden = model.init_hidden(1)\n",
    "inputs = torch.tensor([ind]).to(DEVICE)\n",
    "model.eval()\n",
    "output, _ = model(inputs, hidden)\n",
    "preds = output.view(-1, model.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "for top4 in preds.topk(3).indices:\n",
    "    res = []\n",
    "    for l in top4:\n",
    "        w = vocabulary.idx_to_word[l.item()]\n",
    "        res.append(w)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-marijuana",
   "metadata": {},
   "source": [
    "### quick results\n",
    "\n",
    "test set loss\n",
    "==========\n",
    "\n",
    "EPOCH = 5\n",
    "\n",
    "Basis\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.487\n",
    "\n",
    "SGD\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0 \\\n",
    "p = 2 \\\n",
    "opt = SGD\n",
    "\n",
    "loss = 7.341\n",
    "\n",
    "REG : $\\lambda = 0.1$ \n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.1 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 6.822\n",
    "\n",
    "REG : $\\lambda = 0.01$ \n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.01 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 6.142\n",
    "\n",
    "LSTM + REG : $\\lambda = 0.01$ \n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'LSTM' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.01 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.600\n",
    "\n",
    "REG : $\\lambda = 0.01$ + 4 hidden\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 4 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.01 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.813\n",
    "\n",
    "256 Emb dim\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 256 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0 \\\n",
    "p = 2\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.457\n",
    "\n",
    "POS Encoding + 256 Emb dim\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 256 \\\n",
    "HIDDEN_STATE_SIZE = 200 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0 \\\n",
    "p = 2\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.746\n",
    "\n",
    "EPOCH = 20\n",
    "\n",
    "Basis\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 256 \\\n",
    "HIDDEN_STATE_SIZE = 200 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.01 \\\n",
    "p = 2\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-draft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-anger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('typewriter': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd003343bff8ea9174e4e18dc33629d8cc7123b4a33b966bf5614ca716c9ad2f2e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
