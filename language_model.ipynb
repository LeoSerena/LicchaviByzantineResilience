{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "minus-radiation",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import typing\n",
    "import gc\n",
    "\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.join('.','src')\n",
    ")\n",
    "\n",
    "from src.models import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pharmaceutical-width",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline('CONFIG_MODEL.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextWordPredictorModel(\n",
       "  (embedding_layer): Embedding(10000, 256, padding_idx=0)\n",
       "  (rnn): GRU(256, 200, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=200, out_features=10000, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appropriate-holder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:17<00:00, 404.34it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 400.63it/s]\n",
      "  0%|          | 8/7100 [00:00<01:31, 77.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 0 : 9.209243914375843\n",
      "Eval loss at epoch 0 : 9.209652099820131\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:54<00:00, 129.74it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 396.00it/s]\n",
      "  0%|          | 0/7100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 1 : 6.174411716595502\n",
      "Eval loss at epoch 1 : 5.703722846442164\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1066/7100 [00:08<00:45, 131.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 3390/7100 [00:25<00:27, 133.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 5588/7100 [00:42<00:11, 132.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:54<00:00, 130.94it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 407.48it/s]\n",
      "  0%|          | 0/7100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 2 : 5.527170700153834\n",
      "Eval loss at epoch 2 : 5.513788282541939\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 832/7100 [00:06<00:47, 132.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 3242/7100 [00:24<00:28, 133.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 5347/7100 [00:40<00:13, 128.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:54<00:00, 131.02it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 417.17it/s]\n",
      "  0%|          | 0/7100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 3 : 5.278839957814821\n",
      "Eval loss at epoch 3 : 5.450446317867679\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 372/7100 [00:02<00:51, 129.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 2386/7100 [00:18<00:36, 128.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 4595/7100 [00:34<00:18, 131.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:54<00:00, 129.97it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 416.20it/s]\n",
      "  0%|          | 12/7100 [00:00<01:02, 113.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 4 : 5.127588445838069\n",
      "Eval loss at epoch 4 : 5.4268180019947705\n",
      "updating best metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 110/7100 [00:00<00:53, 131.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2595/7100 [00:20<00:36, 124.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 4805/7100 [00:36<00:17, 132.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 6961/7100 [00:53<00:01, 131.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 524288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7100/7100 [00:54<00:00, 130.92it/s]\n",
      "100%|██████████| 724/724 [00:01<00:00, 417.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss at epoch 5 : 5.016937662782803\n",
      "Eval loss at epoch 5 : 5.413711587039146\n",
      "updating best metric\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "recognized-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6531/6531 [00:08<00:00, 750.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.410678762404665"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "overhead-rover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when they disbanded much of the domestic — were done for the investment aired on july superman escape in the united states through the the bus for a position just when care came to study the year church with the scientology business foundation called it a local bird with a soccer update by sought out of the fort independent and a landmark later residence of around borders and then fortifications in the tower itself with the fish and the building avenue department for the city s capital on the canal but little miles from its cathedral the th century paintings from'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.generate(start_text = 'when')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rural-candidate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextWordPredictorModel(\n",
       "  (embedding_layer): Embedding(10000, 256, padding_idx=0)\n",
       "  (rnn): GRU(256, 200, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=200, out_features=10000, bias=True)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "harmful-entrance",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary +: 'collections.OrderedDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c79f55d78a50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary +: 'collections.OrderedDict'"
     ]
    }
   ],
   "source": [
    "pipeline.model.rnn.state_dict() ++ pipeline.model.linear.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hungry-equivalent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0920, -0.3084,  0.0071,  ..., -0.1118,  0.2542, -0.1783],\n",
       "        [ 0.0453, -0.2914, -0.1204,  ..., -0.1137,  0.3070, -0.1746],\n",
       "        [ 0.0864, -0.1459, -0.0077,  ..., -0.0059, -0.0561,  0.0088],\n",
       "        ...,\n",
       "        [ 0.2158, -0.2601, -0.2930,  ...,  0.2634, -0.0085,  0.1097],\n",
       "        [ 0.2740, -0.1428,  0.1697,  ...,  0.2707,  0.0208,  0.0931],\n",
       "        [ 0.0315, -0.1839,  0.0440,  ...,  0.1020, -0.0595,  0.2213]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.model.linear.state_dict()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "revolutionary-revelation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.model.criterion.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "appreciated-patch",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-startup",
   "metadata": {},
   "source": [
    "## Global Variables & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "assert torch.cuda.is_available()\n",
    "from apex import amp, optimizers\n",
    "\n",
    "MIN_SEQ_LEN = 2\n",
    "MAX_SEQ_LEN = 20\n",
    "\n",
    "RNN_TYPE = 'LSTM'\n",
    "BATCH_SIZE = 16\n",
    "NUM_RNN_LAYERS = 4\n",
    "EMB_SIZE = 256\n",
    "HIDDEN_STATE_SIZE = 200\n",
    "DROPOUT = 0.5\n",
    "fp16 = True\n",
    "POS_ENCODING = False\n",
    "STARTING_LR = 5e-4\n",
    "LAMBDA = 0\n",
    "p = 1\n",
    "\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "\n",
    "# for reproducibility\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-excuse",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "train_text = ' '.join(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-temple",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary = FromRawTextVocabulary(\n",
    "    text = train_text,\n",
    "    tokenizer = tokenizer,\n",
    "    text_cleaner = None,\n",
    "    max_voc_size = 10000,\n",
    "    min_word_occ = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-barcelona",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "\n",
    "train_text = ' '.join(train_iter)\n",
    "val_text = ' '.join(val_iter)\n",
    "test_text = ' '.join(test_iter)\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = train_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "val_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = val_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    vocabulary = vocabulary,\n",
    "    text = test_text,\n",
    "    max_seq_length = MAX_SEQ_LEN + 1,\n",
    "    min_seq_length = MIN_SEQ_LEN,\n",
    "    device = DEVICE\n",
    ")\n",
    "\n",
    "del train_text\n",
    "del val_text\n",
    "del test_text\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = False,\n",
    "    pin_memory = False,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_weights(weights, m_ = 0.01, M_ = 1):\n",
    "    weights = 1 / weights\n",
    "    M, m = max(weights), min(weights)\n",
    "    return (np.array(weights) - m) * (M_ - m_) / (M - m) + m_\n",
    "\n",
    "weights = map_weights(np.array(list(vocabulary.vocab.values())))\n",
    "weights = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-waterproof",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NextWordPredictorModel(\n",
    "    type_of_rnn = RNN_TYPE,\n",
    "    emb_dim  = EMB_SIZE,\n",
    "    vocab_size = vocabulary.get_vocab_size(),\n",
    "    num_rnn_hidden_layers = NUM_RNN_LAYERS,\n",
    "    hidden_state_size = HIDDEN_STATE_SIZE,\n",
    "    dropout = DROPOUT,\n",
    "    device = DEVICE,\n",
    "    weight = weights,\n",
    "    positional_encoding = POS_ENCODING\n",
    ").to(DEVICE)\n",
    "\n",
    "# need to setup the optimizer there because of the amp initialization\n",
    "model.optimizer = torch.optim.Adam(model.parameters(), lr = STARTING_LR)\n",
    "\n",
    "if fp16:\n",
    "    model, model.optimizer = amp.initialize(\n",
    "        model,\n",
    "        model.optimizer,\n",
    "        opt_level = 'O1' # https://nvidia.github.io/apex/amp.html\n",
    "    )\n",
    "\n",
    "model.scheduler = torch.optim.lr_scheduler.StepLR(model.optimizer, 1.0, gamma=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-webmaster",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-monroe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = model.fit(\n",
    "    train_dataloader = train_dataloader,\n",
    "    eval_dataloader = val_dataloader,\n",
    "    num_epochs = 20,\n",
    "    fp16 = fp16,\n",
    "    p = p,\n",
    "    lambda_ = LAMBDA,\n",
    "    early_stopping = True,\n",
    "    early_stopping_patience = 2,\n",
    "    early_stopping_metric = 'val_loss',\n",
    "    early_stopping_metric_best = 'min', # if lower is better (like for loss)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics).T\n",
    "plt.figure()\n",
    "plt.plot(df['train_loss'])\n",
    "plt.plot(df['val_loss'])\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-scout",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Historians write in the context of their own time and with due regard to the current dominant ideas of how to interpret the past'\n",
    "ind = [train_dataset.get_idx(w.lower()) for w in sent.split(' ')]\n",
    "print(ind)\n",
    "hidden = model.init_hidden(1)\n",
    "inputs = torch.tensor([ind]).to(DEVICE)\n",
    "model.eval()\n",
    "output, _ = model(inputs, hidden)\n",
    "preds = output.view(-1, model.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "for top4 in preds.topk(3).indices:\n",
    "    res = []\n",
    "    for l in top4:\n",
    "        w = vocabulary.idx_to_word[l.item()]\n",
    "        res.append(w)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-marijuana",
   "metadata": {},
   "source": [
    "### quick results\n",
    "\n",
    "test set loss\n",
    "==========\n",
    "\n",
    "EPOCH = 5\n",
    "\n",
    "Basis\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.487\n",
    "\n",
    "SGD\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0 \\\n",
    "p = 2 \\\n",
    "opt = SGD\n",
    "\n",
    "loss = 7.341\n",
    "\n",
    "REG : $\\lambda = 0.1$ \n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.1 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 6.822\n",
    "\n",
    "REG : $\\lambda = 0.01$ \n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.01 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 6.142\n",
    "\n",
    "LSTM + REG : $\\lambda = 0.01$ \n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'LSTM' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.01 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.600\n",
    "\n",
    "REG : $\\lambda = 0.01$ + 4 hidden\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 4 \\\n",
    "EMB_SIZE = 128 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.01 \\\n",
    "p = 2 \\\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.813\n",
    "\n",
    "256 Emb dim\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 256 \\\n",
    "HIDDEN_STATE_SIZE = 100 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0 \\\n",
    "p = 2\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.457\n",
    "\n",
    "POS Encoding + 256 Emb dim\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 256 \\\n",
    "HIDDEN_STATE_SIZE = 200 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0 \\\n",
    "p = 2\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.746\n",
    "\n",
    "EPOCH = 20\n",
    "\n",
    "Basis\n",
    "--------\n",
    "\n",
    "RNN_TYPE = 'GRU' \\\n",
    "BATCH_SIZE = 16 \\\n",
    "NUM_RNN_LAYERS = 2 \\\n",
    "EMB_SIZE = 256 \\\n",
    "HIDDEN_STATE_SIZE = 200 \\\n",
    "DROPOUT = 0.5 \\\n",
    "fp16 = True \\\n",
    "POS_ENCODING = False \\\n",
    "STARTING_LR = 1e-3 \\\n",
    "LAMBDA = 0.01 \\\n",
    "p = 2\n",
    "opt = ADAM\n",
    "\n",
    "loss = 5.976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-draft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-anger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('typewriter': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd003343bff8ea9174e4e18dc33629d8cc7123b4a33b966bf5614ca716c9ad2f2e1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
